from google.colab import files
import firebase_admin
from firebase_admin import credentials, storage
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

# Hardcoded service account key JSON
service_account_key = {
    "type": "service_account",
    "project_id": "fyp-login-regis",
    "private_key_id": "a4d5ce3d6e6cac825d5712bf203c4c804ab4db0c",
    "private_key": "-----BEGIN PRIVATE KEY-----\n...........\n-----END PRIVATE KEY-----\n",// private key is removed for privacy issues
    "client_email": "firebase-adminsdk-lt3ps@fyp-login-regis.iam.gserviceaccount.com",
    "client_id": "103546225454042492817",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
    "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-lt3ps%40fyp-login-regis.iam.gserviceaccount.com",
    "universe_domain": "googleapis.com"
}

# Initialize Firebase Admin SDK with the uploaded JSON key file
cred = credentials.Certificate(service_account_key)
firebase_admin.initialize_app(cred, {
    'storageBucket': 'fyp-login-regis.appspot.com'
})

from google.colab import drive
drive.mount('/content/drive')

# Load the trained model from Google Drive
model_path = '/content/drive/My Drive/FYP_training.h5'
model = load_model(model_path)
print("Model loaded from .h5 format.")

# Define class names (same as used during training)
class_names = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']

# Initialize the bucket
bucket = storage.bucket()

# Loop
while True:
    # List files in the 'images' folder
    blobs = bucket.list_blobs(prefix='images/')
    file_names = [blob.name for blob in blobs]

    print("Available images:")
    for i, name in enumerate(file_names):
        print(f"{i}: {name}")

    # Let user choose a file
    index = int(input("Enter the number of the file you want to select: "))
    selected_file = file_names[index]

    # Download the selected image
    image_blob = bucket.blob(selected_file)
    image_blob.download_to_filename('downloaded_image.jpg')

    # Load and preprocess the image
    image = cv2.imread('downloaded_image.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib

    # Display the image
    plt.imshow(image)
    plt.axis('off')  # Hide axis
    plt.show()

    # Preprocess the image
    resized_image = cv2.resize(image, (48, 48))
    input_image = np.expand_dims(resized_image, axis=0)  # Add batch dimension
    input_image = input_image / 255.0  # Normalize pixel values

    # Make predictions using the loaded model
    predictions = model.predict(input_image)

    # Get the predicted class index
    predicted_class = np.argmax(predictions[0])

    # Display the predicted class
    print(f"Predicted class: {class_names[predicted_class]}")

    # Save the processed image
    processed_image_path = 'processed_image.jpg'
    cv2.imwrite(processed_image_path, resized_image)

    # Save the prediction result to a text file
    result_text = f"Predicted class: {class_names[predicted_class]}"
    result_file_path = 'prediction_result.txt'

    with open(result_file_path, 'w') as file:
        file.write(result_text)

    # Define the destination paths in Firebase Storage
    destination_image_blob_name = f'processed_images/{selected_file}'
    destination_result_blob_name = f'prediction_results/{selected_file}.txt'

    # Upload the processed image to Firebase Storage
    processed_image_blob = bucket.blob(destination_image_blob_name)
    processed_image_blob.upload_from_filename(processed_image_path)

    # Upload the prediction result to Firebase Storage
    result_blob = bucket.blob(destination_result_blob_name)
    result_blob.upload_from_filename(result_file_path)

    # Ask if user wants to process another image
    another = input("Do you want to process another image? (yes/no): ")
    if another.lower() != 'yes':
        break
