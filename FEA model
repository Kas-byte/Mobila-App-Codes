from google.colab import files
import firebase_admin
from firebase_admin import credentials, storage
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

# Hardcoded service account key JSON edited out for privacy reasons
service_account_key = {
    .........
}

# Initialize Firebase Admin SDK with the uploaded JSON key file
cred = credentials.Certificate(service_account_key)
firebase_admin.initialize_app(cred, {
    'storageBucket': 'fyp-login-regis.appspot.com'
})

from google.colab import drive
drive.mount('/content/drive')

# Load the trained model from Google Drive
model_path = '/content/drive/My Drive/FYP_training.h5'
model = load_model(model_path)
print("Model loaded from .h5 format.")

# Define class names (same as used during training)
class_names = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']


bucket = storage.bucket()

while True:
   
    blobs = bucket.list_blobs(prefix='images/')
    file_names = [blob.name for blob in blobs]

    print("Available images:")
    for i, name in enumerate(file_names):
        print(f"{i}: {name}")

 
    index = int(input("Enter the number of the file you want to select: "))
    selected_file = file_names[index]

  
    image_blob = bucket.blob(selected_file)
    image_blob.download_to_filename('downloaded_image.jpg')


    image = cv2.imread('downloaded_image.jpg')
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib


    plt.imshow(image)
    plt.axis('off')  # Hide axis
    plt.show()


    resized_image = cv2.resize(image, (48, 48))
    input_image = np.expand_dims(resized_image, axis=0)  # Add batch dimension
    input_image = input_image / 255.0  # Normalize pixel values

 
    predictions = model.predict(input_image)


    predicted_class = np.argmax(predictions[0])

 
    print(f"Predicted class: {class_names[predicted_class]}")


    processed_image_path = 'processed_image.jpg'
    cv2.imwrite(processed_image_path, resized_image)


    result_text = f"Predicted class: {class_names[predicted_class]}"
    result_file_path = 'prediction_result.txt'

    with open(result_file_path, 'w') as file:
        file.write(result_text)


    destination_image_blob_name = f'processed_images/{selected_file}'
    destination_result_blob_name = f'prediction_results/{selected_file}.txt'


    processed_image_blob = bucket.blob(destination_image_blob_name)
    processed_image_blob.upload_from_filename(processed_image_path)

  
    result_blob = bucket.blob(destination_result_blob_name)
    result_blob.upload_from_filename(result_file_path)


    another = input("Do you want to process another image? (yes/no): ")
    if another.lower() != 'yes':
        break
