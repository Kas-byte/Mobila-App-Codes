import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
import zipfile
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Upload and extract the dataset
uploaded = files.upload()
with zipfile.ZipFile('FER-2013 emotion data.zip', 'r') as zip_ref:
    zip_ref.extractall('dataset')
# Prepare the datasets
train_data_dir = 'dataset/train'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    image_size=(48, 48),
    batch_size=32,
    label_mode='int'
)

test_data_dir = 'dataset/test'
test_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    test_data_dir,
    image_size=(48, 48),
    batch_size=32,
    label_mode='int'
)

class_names = train_dataset.class_names
print("Class names:", class_names)

# Display sample images
for images, labels in train_dataset.take(1):
    images = images.numpy()
    labels = labels.numpy()

plt.figure(figsize=(10, 10))
for i in range(min(10, len(images))):
    image = images[i]
    if image.max() > 1 or image.min() < 0:
        image = (image - image.min()) / (image.max() - image.min())
        print(f"Max value in the image: {image.max()}")
        print(f"Min value in the image: {image.min()}")
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(image, cmap=plt.cm.binary)
    plt.xlabel(class_names[labels[i]])

plt.show()

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(1./255, input_shape=(48, 48, 3)),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10)
])

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Print model summary
model.summary()

# Train the model
model.fit(train_dataset, epochs=6, validation_data=test_dataset)

# Evaluate the model
test_loss, test_acc = model.evaluate(test_dataset, verbose=2)
print('\nTest accuracy:', test_acc)
print(f"Test Loss: {test_loss}")

# Optionally, calculate and display additional metrics
from sklearn.metrics import classification_report, confusion_matrix

# Generate predictions for the test dataset
predictions = model.predict(test_dataset)

# Convert predictions to class labels
predicted_classes = np.argmax(predictions, axis=1)

# Extract true labels from the test dataset
true_classes = np.concatenate([y for x, y in test_dataset], axis=0)

# Print classification report
print(classification_report(true_classes, predicted_classes, target_names=class_names))

# Print confusion matrix
conf_mat = confusion_matrix(true_classes, predicted_classes)
print("Confusion Matrix:")
print(conf_mat)

h5_save_path = '/content/drive/My Drive/FYP_training.h5'
keras_save_path = '/content/drive/My Drive/FYP_training.keras'

# Save model in HDF5 format
model.save(h5_save_path)
print(f"Model saved in HDF5 format to {h5_save_path}")

# Save model in TensorFlow Keras format
model.save(keras_save_path)
print(f"Model saved in TensorFlow Keras format to {keras_save_path}")
